# Specifications

## Overview

A local web application for learning a foreign language (initially Slovenian) aimed at an American English speaker. The app teaches vocabulary and grammar *in context* by presenting glossed sentences and lemma (word) pages. Content is generated by an LLM on demand and cached in a local SQLite database.

---

## Goals and Non-goals

### Goals

- Teach foreign-language vocabulary and grammar in context to an American English speaker.
- Focus on reading comprehension (listening is a future goal).
- Generate content on demand to minimize LLM costs; cache all generated content.

### Non-goals

- Writing or speaking practice.
- Spaced repetition or progress tracking.

---

## Technology Stack

| Component        | Technology                          |
|------------------|-------------------------------------|
| Back-end         | Flask (Python)                      |
| Front-end        | HTML, CSS, HTMX                     |
| Database         | SQLite                              |
| Program / deps   | `uv` (`pyproject.toml`)             |
| Forms / CSRF     | Flask-WTF (CSRFProtect)             |
| RSS fetching     | `requests` + `feedparser`           |
| Content generation | LLM (OpenAI; default model `gpt-5-nano`) |

---

## Terminology

### Language

A target foreign language, identified by a two-letter code in URLs and the database (e.g., `sl` for Slovenian, `de` for German).

### Sentence

A single normalized sentence of foreign-language text.

- **Normalization**: Unicode NFKC with internal whitespace collapsed (no double spaces) and leading/trailing whitespace trimmed.
- **Invariant**: All sentences are normalized before being inserted into the database, so all stored sentence text is already normalized.
- **Sources**: (The first sentences of) RSS headlines from configured feeds.
- **Hash slug**: The first 10 hex characters of the SHA-256 hash of the normalized text, lowercased.
- **URL pattern**: `/<lang>/sentence/<hash_slug>` (e.g., `/sl/sentence/a1b2c3d4e5`).


### Token

A clickable unit within a displayed sentence.

- **Tokenization**:
  - Tokenization is produced by the LLM as part of sentence page generation, not by a local rule-based tokenizer (e.g., NLTK or spaCy).
  - The LLM must return tokens in reading order such that concatenating token surfaces (inserting appropriate whitespace between tokens) reconstructs the original sentence text.
  - The LLM must return multi-word proper nouns as a single token spanning internal whitespace (e.g., `New York`).
  - The LLM must return punctuation as separate tokens.
- **Surface vs normalized form**:
  - Display uses the original surface string as returned by the LLM.
  - Database lookups assume stored sentence text and lemma identifiers are already normalized.
- **Punctuation tokens**: Displayed but not clickable; have no associated lemma.


### Lemma

The canonical dictionary form of a token.

- **Normalization**: Unicode NFKC with internal whitespace collapsed (no double spaces) and leading/trailing whitespace trimmed.
- **Invariant**: All lemma identifier strings stored in the database are already normalized.
- **URL input**: Lemma path segments are user-provided; the server must normalize the URL-decoded lemma string before database lookup.

| Part of speech           | Lemma form                                      |
|--------------------------|-------------------------------------------------|
| Common noun              | Nominative singular, lowercase                  |
| Adjective                | Masculine nominative singular, lowercase        |
| Verb                     | Infinitive, lowercase                           |
| Adverb, preposition, conjunction, etc. | Lowercase                        |
| Proper noun              | Full string with original capitalization        |
| Punctuation              | No lemma (not stored)                           |

- **Identity**: A lemma is uniquely identified in the database by `(language, normalized_lemma_string)`.
- **URL pattern**: `/<lang>/lemma/<normalized_lemma>` (URL-encoded)
- **Lookup**: The server URL-decodes and normalizes the lemma segment before looking up `lemmas.normalized_lemma`.

---

## User Model

### Overview

- Login (username + password) is required for access.
- The app does **not** track individual user progress; cached content and access counts are shared globally across all users.
- Multiple user accounts may exist, but they share a single content database.
- Each user has a `default_language` preference, which affects the sentence page displayed after login or upon accessing the path `/`.

### Credential Management

- User records are stored in the SQLite database (`users` table).
- Users are created, updated, or deleted via a command-line admin script (not via the web UI).
- There is no self-service registration or password reset.

### Password Storage

- Passwords are hashed with a salted algorithm (e.g., PBKDF2-SHA256 via Werkzeug).
- The `users` table stores: `username`, `password_hash`, `default_language`.

### Session Policy

- Flask session cookies maintain login state.
- Sessions are persistent ("remember me") and do not expire until the browser clears cookies or the server secret key changes.
- Cookies are `HttpOnly`, `Secure` when served over HTTPS (disabled for local HTTP), and scoped as a host-only cookie.
- Every request (except `/login`) requires a valid session; unauthenticated requests redirect to `/login`.
- CSRF protection is enabled for login and all state-changing actions.

---

## Pages

### Login Page

- **URL**: `/login`
- Displays a username/password form.
- On success, redirects to `/<default_language>/` (the user's default language sentence list).
- On failure, redisplays with an error message.

### Sentence List Page

- **URL**: `/<lang>/` (e.g., `/sl/`)
- Lists sentences in the database for the given language.
- Includes an "Update" button above the list that fetches new RSS headlines for the current language from enabled feeds and inserts any new sentences.
  - Update is a state-changing action and must be CSRF-protected.
  - Update does not push a new browser history entry and does not change the URL.
- Each row shows:
  - The sentence text.
  - Parenthesized access count (number of times the sentence detail page was fully loaded).
- Sorted by insert time, newest first.
- Limited to 100 sentences (no pagination).
- Clicking a sentence navigates to its detail page. Words/lemmas are not separately clickable.

### Sentence Detail Page

- **URL**: `/<lang>/sentence/<hash_slug>`
- **Layout** (top to bottom):

  1. **Glossed sentence** (bold):
     - Each token displayed with its gloss directly below (interlinear style, inline flow).
     - Gloss = literal translation + morphological tags.
     - Allowable Leipzig Glossing tags: `1`, `2`, `3`, `sg`, `du`, `pl`, `nom`, `gen`, `dat`, `acc`, `ins`, `loc`, `refl`, `m`, `f`, `n`.
     - Each word token links to its lemma page. Punctuation tokens are not clickable.

  2. **Proper noun definitions** (optional):
     - A list of proper nouns in the sentence unfamiliar to most Americans.
         - Exclude globally famous proper nouns like `Paris` or `Mozart`
         - Include all local figures, places, or organizations
         - Include famous places if their English name is different, e.g., `Vienna` is famous, but its Slovenian name `Dunaj` should be explained.
     - Each entry: proper noun (nominative case) + brief definition/explanation.
     - Omitted if the sentence contains no unfamiliar proper nouns.

  3. **Grammar notes** (optional):
     - Surprising grammar features for an English speaker.
     - Excludes basics that apply to most languages (e.g., adjective gender agreement, verb number agreement).
     - Focuses on tense/mood/aspect differences, unusual word order, constructions without direct English equivalents.
     - Omitted if the sentence contains only straightforward grammar.

  4. **Regenerate controls**:
     - A dropdown to select an LLM model.
     - A button labeled "Regenerate".
     - A label showing which model generated the current content.
     - Clicking "Regenerate" re-generates all content for the page, replaces the cached data, and reloads. No history is kept.

- **Access counting**: Each full page load (not HTMX partial) increments the sentence's access count by 1.

### Lemma Detail Page

- **URL**: `/<lang>/lemma/<normalized_lemma>` (URL-encoded)
- **Lookup**: The server URL-decodes and normalizes the lemma segment before looking up `lemmas.normalized_lemma`.
- **Layout** (top to bottom):

  1. **Lemma and translation**:
     - The lemma (bold).
     - A concise English translation.

  2. **Related words** (optional, max 8):
     - A list of related words/phrases with translations.
     - Each entry includes a short note explaining why it is related (e.g., etymological relation, false friend, near-synonym distinction).
     - Entries may not always be lemmas in the dictionary sense; each entry includes a `normalized_lemma` link target and links to that lemma page.
     - Excludes inflected/conjugated forms of the same lemma.
     - May be shorter or omitted if no good candidates.

  3. **Regenerate controls**: Same as sentence detail page.

- **Access counting**: Each full page load increments the lemma's access count by 1.

### Root Page

- **URL**: `/`
- Redirects to `/login` if not logged in.
- Otherwise redirects to `/<default_language>/` (the user's default language).

---

## Data Storage (SQLite)

### Purpose

- Cache all LLM-generated content so pages render instantly on repeat visits.
- Track access counts for sentences and lemmas.
- Track processed RSS articles to avoid duplicates.
- Store user credentials.

### Tables (conceptual)

| Table           | Key columns                                                                 |
|-----------------|-----------------------------------------------------------------------------|
| `users`         | `username`, `password_hash`, `default_language`                             |
| `sentences`     | `id`, `language`, `hash`, `text`, `gloss_json`, `proper_nouns_json`, `grammar_notes_json`, `model_used`, `schema_version`, `access_count`, `created_at`, `updated_at` |
| `lemmas`        | `id`, `language`, `normalized_lemma`, `translation`, `related_words_json`, `model_used`, `schema_version`, `access_count`, `created_at`, `updated_at` |
| `rss_articles`  | `feed_id`, `article_id`                                    |

### Schema (DDL)

All cached payload fields are stored as JSON in `TEXT` columns.

The database stores a versioning field to control cache invalidation:

- `schema_version` (integer): bumped when the JSON structure changes.

Cached content with mismatched `schema_version` is treated as a cache miss and regenerated on next access.

```sql
CREATE TABLE IF NOT EXISTS users (
  username TEXT PRIMARY KEY,
  password_hash TEXT NOT NULL,
  default_language TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS sentences (
  id INTEGER PRIMARY KEY,
  language TEXT NOT NULL,
  hash TEXT NOT NULL,
  text TEXT NOT NULL,
  gloss_json TEXT,
  proper_nouns_json TEXT,
  grammar_notes_json TEXT,
  model_used TEXT,
  schema_version INTEGER NOT NULL,
  access_count INTEGER NOT NULL DEFAULT 0,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  UNIQUE(language, hash)
);

CREATE INDEX IF NOT EXISTS idx_sentences_language_created_at
  ON sentences(language, created_at DESC);

CREATE TABLE IF NOT EXISTS lemmas (
  id INTEGER PRIMARY KEY,
  language TEXT NOT NULL,
  normalized_lemma TEXT NOT NULL,
  translation TEXT,
  related_words_json TEXT,
  model_used TEXT,
  schema_version INTEGER NOT NULL,
  access_count INTEGER NOT NULL DEFAULT 0,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  UNIQUE(language, normalized_lemma)
);

CREATE INDEX IF NOT EXISTS idx_lemmas_language_created_at
  ON lemmas(language, created_at DESC);

CREATE TABLE IF NOT EXISTS rss_articles (
  feed_id TEXT NOT NULL,
  article_id TEXT NOT NULL,
  PRIMARY KEY(feed_id, article_id)
);
```

Foreign keys are not required for token-to-lemma relationships because tokenization and lemma links are stored inside cached JSON payloads.

---

## RSS Ingestion

### Behavior

- RSS headlines are fetched only when the user clicks the "Update" button on the sentence list page for a language.
- The update operation fetches headlines from configured, enabled feeds for that language.
- RSS fetching uses `requests` for HTTP and `feedparser` for parsing.
- For each new article (not previously seen):
  1. Extract headline text.
  2. Treat the headline text as one logical sentence.
  3. Normalize the sentence.
  4. Insert the sentence into the `sentences` table (content generated lazily on first access).

### Feed Configuration

- Feeds are defined in a configuration file `feeds.yaml`.
- Each feed specifies: URL, language code, enabled/disabled flag.
- Articles are deduplicated by the RSS item's `id`/GUID field as returned by the RSS parser.
  - If the feed does not provide an `id`/GUID, fall back to a hash of the item's link URL.

---

## LLM Integration

### Supported Models

- OpenAI models: `gpt-5-nano` (default), `gpt-5-mini`, and `gpt-5`.

### Configuration

- API keys provided via environment variables: `OPENAI_API_KEY`.
- Model selection stored per cached page (so regeneration can use a different model).

### Request Handling

- Timeout: 60 seconds.
- Retries: up to 2 retries on transient errors (429, 500, 502, 503, 504).
- Malformed output: if LLM returns invalid JSON, attempt one retry; if still invalid, display an error and do not cache.

### Cost Controls

- No cost control.

---

## Navigation and Browser History

- All page navigations (sentence list → sentence detail → lemma detail) must push to browser history.
- The browser back button must return to the previous page correctly.
- HTMX is used for interactivity; use `hx-push-url="true"` or full-page navigations to ensure history works.

### Regeneration behavior

- Regeneration is an HTMX partial update that replaces page content in place.
- Regeneration does not push a new browser history entry and does not change the URL.
- Regeneration does not increment access count.

---

## Deployment

### Local Deployment

- The app is designed for local/single-machine deployment.
- Run via Flask development server or a production WSGI server (e.g., gunicorn).

### Environment Variables

| Variable            | Purpose                                      |
|---------------------|----------------------------------------------|
| `SECRET_KEY`        | Flask session signing key                    |
| `DATABASE_PATH`     | Path to SQLite database file                 |
| `OPENAI_API_KEY`    | OpenAI API key                               |

### Setup Steps

1. Create/initialize the SQLite database via `init_db.py`.
2. Create at least one user via the admin CLI.
3. Set environment variables.
4. Start the Flask server.

---

## Implementation prerequisites (required to generate the implementation)

The following decisions define the contracts required to generate a correct and complete implementation:

### LLM output contracts (JSON schemas)

All cached LLM outputs must validate against the relevant schema version before being cached.

#### Sentence-detail generation (`schema_version = 1`)

Top-level object:

- `schema_version` (number): `1`
- `sentence_text` (string): must equal the normalized sentence text stored in `sentences.text`.
  - This intentionally duplicates the stored sentence string so cached payloads are self-contained and so the server can validate that the LLM output corresponds to the requested sentence.
- `tokens` (array of `Token`)
- `proper_nouns` (array of `ProperNoun`)
- `grammar_notes` (array of `GrammarNote`)
- `model_used` (string)

`Token` object:

- `leading` (string): either `""` or `" "` (or other whitespace) so that concatenating `leading + surface` for all tokens reconstructs `sentence_text`
- `surface` (string)
- `is_punct` (boolean)
- If `is_punct` is `false`:
  - `lemma` (string)
  - `pos` (string)
  - `gloss` (string)
  - `tags` (array of strings): subset of allowable Leipzig tags

`ProperNoun` object:

- `nominative` (string)
- `definition` (string)

`GrammarNote` object:

- `title` (string)
- `note` (string)

JSON Schema:

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "SentenceDetailGenerationV1",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "schema_version",
    "sentence_text",
    "tokens",
    "proper_nouns",
    "grammar_notes",
    "model_used"
  ],
  "properties": {
    "schema_version": {
      "const": 1
    },
    "sentence_text": {
      "type": "string",
      "minLength": 1,
      "description": "Must equal the normalized sentence text stored in sentences.text"
    },
    "tokens": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": ["leading", "surface", "is_punct"],
        "properties": {
          "leading": {
            "type": "string",
            "description": "Whitespace to place before surface; concatenating leading+surface for all tokens reconstructs sentence_text"
          },
          "surface": {
            "type": "string",
            "minLength": 1
          },
          "is_punct": {
            "type": "boolean"
          },
          "lemma": {
            "type": "string",
            "minLength": 1
          },
          "pos": {
            "type": "string",
            "minLength": 1
          },
          "gloss": {
            "type": "string",
            "minLength": 1
          },
          "tags": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "1",
                "2",
                "3",
                "sg",
                "du",
                "pl",
                "nom",
                "gen",
                "dat",
                "acc",
                "ins",
                "loc",
                "refl",
                "m",
                "f",
                "n"
              ]
            }
          }
        },
        "allOf": [
          {
            "if": {
              "properties": { "is_punct": { "const": false } },
              "required": ["is_punct"]
            },
            "then": {
              "required": ["lemma", "pos", "gloss", "tags"]
            },
            "else": {
              "allOf": [
                { "not": { "required": ["lemma"] } },
                { "not": { "required": ["pos"] } },
                { "not": { "required": ["gloss"] } },
                { "not": { "required": ["tags"] } }
              ]
            }
          }
        ]
      }
    },
    "proper_nouns": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": ["nominative", "definition"],
        "properties": {
          "nominative": { "type": "string", "minLength": 1 },
          "definition": { "type": "string", "minLength": 1 }
        }
      }
    },
    "grammar_notes": {
      "type": "array",
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": ["title", "note"],
        "properties": {
          "title": { "type": "string", "minLength": 1 },
          "note": { "type": "string", "minLength": 1 }
        }
      }
    },
    "model_used": {
      "type": "string",
      "minLength": 1
    }
  }
}
```

#### Lemma-page generation (`schema_version = 1`)

Top-level object:

- `schema_version` (number): `1`
- `lemma` (string)
- `normalized_lemma` (string): already normalized; used for storage and URLs
- `translation` (string)
- `related_words` (array of `RelatedWord`, length <= 8)
- `model_used` (string)

`RelatedWord` object:

- `word` (string)
- `normalized_lemma` (string): link target for a lemma page; may differ from `word`
- `translation` (string)
- `note` (string): explains why the related entry is included

JSON Schema:

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "LemmaPageGenerationV1",
  "type": "object",
  "additionalProperties": false,
  "required": [
    "schema_version",
    "lemma",
    "normalized_lemma",
    "translation",
    "related_words",
    "model_used"
  ],
  "properties": {
    "schema_version": {
      "const": 1
    },
    "lemma": {
      "type": "string",
      "minLength": 1
    },
    "normalized_lemma": {
      "type": "string",
      "minLength": 1,
      "description": "Already normalized; used for storage and URLs"
    },
    "translation": {
      "type": "string",
      "minLength": 1
    },
    "related_words": {
      "type": "array",
      "maxItems": 8,
      "items": {
        "type": "object",
        "additionalProperties": false,
        "required": ["word", "normalized_lemma", "translation", "note"],
        "properties": {
          "word": { "type": "string", "minLength": 1 },
          "normalized_lemma": { "type": "string", "minLength": 1 },
          "translation": { "type": "string", "minLength": 1 },
          "note": { "type": "string", "minLength": 1 }
        }
      }
    },
    "model_used": {
      "type": "string",
      "minLength": 1
    }
  }
}
```

#### Invalid JSON behavior

- On JSON parse or validation failure: attempt one retry.
- If still invalid: show a user-visible error and do not cache.

### SQLite schema DDL

The SQLite schema is defined in the Data Storage section.

### Admin CLI for users

Users are managed via a CLI script named `users` with the following commands:

- `users list`
- `users create --username <username> --password <password> --default-language <lang>`
- `users update --username <username> [--password <password>] [--default-language <lang>]`
- `users delete --username <username>`

`default_language` validation: lowercase two-letter language code matching `^[a-z]{2}$`. It can be changed via `users update`.

### `feeds.yaml` format

`./feeds.yaml` contains a list of feed objects. 
Feed object format:
- `id` (string, required)
- `url` (string, required)
- `language` (string, required; two-letter code)
- `enabled` (boolean, optional; default true)

Multiple feeds with the same language are allowed.

### No sentence splitting

RSS headlines are treated as one logical sentence, even if there are multiple grammatical sentences.

### HTMX navigation behavior

- Normal navigations push browser history.
- `Regenerate` is an HTMX partial update that replaces page content in place.
- Regeneration does not push a new history entry and does not change the URL.

### Security defaults

- CSRF protection uses Flask-WTF `CSRFProtect`.
- All HTML form submissions that change state must include a CSRF token.
- All HTMX requests that change state must include a CSRF token (e.g., via an `X-CSRFToken` header).
- Session cookies are `HttpOnly` and `SameSite=Lax`.
- `Secure` is enabled when served over HTTPS and disabled for local HTTP.
